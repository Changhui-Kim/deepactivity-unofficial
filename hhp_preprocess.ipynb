{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0589e3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127848 253644\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "OUTPUT_PERSONS_PATH = \"C:/Users/user/PTV_Intern/src/DeepAM/dataset/persons_info.csv\"\n",
    "hh_df = pd.read_csv(\"C:/Users/user/PTV_Intern/data/raw/NHTS_US_2017/hhpub.csv\")\n",
    "per_df = pd.read_csv(\"C:/Users/user/PTV_Intern/data/raw/NHTS_US_2017/perpub.csv\")\n",
    "trip_df = pd.read_csv(\"C:/Users/user/PTV_Intern/data/raw/NHTS_US_2017/trippub.csv\")\n",
    "hh_df = hh_df[hh_df['HHSIZE']<=5]\n",
    "per_df = per_df[per_df['HHSIZE']<=5]\n",
    "print(len(hh_df), len(per_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a048722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Attributes of Interestfor each dataframe ---\n",
    "nhts_household_columns = [\n",
    "    'HOUSEID',      # (인덱스용)\n",
    "    'HHFAMINC',     # 1. Household Income\n",
    "    'HHSIZE',       # 2. Household Size\n",
    "    'HHVEHCNT',     # 3. Household Vehicles\n",
    "    'HOMEOWN',      # 4. Home Ownership Status\n",
    "    'STDCNT',       # 5. Household Students (SCHTYP로 계산)\n",
    "    'DRVRCNT',      # 6. Household Licensed Drivers\n",
    "    'LIF_CYC',      # 7. Household Life Cycle Stage\n",
    "    'WRKCOUNT',     # 8. Household Employed Members\n",
    "    'URBRUR',       # 9. Type of Residence (URBAN은 4개 분류, URBRUR은 2개 분류)\n",
    "    'HBRESDN',      # 10. Housing Density\n",
    "    'HBPPOPDN',     # 11. Population Density\n",
    "    'HBHTNRNT',     # 12. Renter-Occupied Housing Ratio\n",
    "    # '',           # (없음) Housing Status\n",
    "]\n",
    "nhts_person_columns = [\n",
    "    'HOUSEID',      # (인덱스용)\n",
    "    'PERSONID',     # (인덱스용)\n",
    "    'DRIVER',       # 1. Driver's License Status\n",
    "    'EDUC',         # 2. Education Level\n",
    "    'OCCAT',        # 3. Job Category\n",
    "    'R_SEX_IMP',    # 4. Gender\n",
    "    'R_AGE_IMP',    # 5. Age\n",
    "    'R_RACE',       # 6. Racial/Ethnic Identity\n",
    "    'PTUSED',       # 7. PTUSED\n",
    "    'R_RELAT',      # 8. Household Role\n",
    "    'GT1JBLWK',     # 9. (Family에선 제외) Number of Jobs\n",
    "    'WORKER',       # 10. Employment Status\n",
    "    'WRK_HOME',     # 11. (Family에선 제외) Employment Location Type\n",
    "    # 'GRADE',        # (없음) Current School Grade Level\n",
    "    # '',             # (없음) Number of Workdays\n",
    "]\n",
    "# Other Household Members Info. 블럭 구성시 필요한 9개 feature\n",
    "family_attributes = [\n",
    "    'HOUSEID',      # (인덱스용)\n",
    "    'PERSONID',     # (인덱스용)\n",
    "    'DRIVER',       # 1. Driver's License Status\n",
    "    'EDUC',         # 2. Education Level\n",
    "    'OCCAT',        # 3. Job Category\n",
    "    'R_SEX_IMP',    # 4. Gender\n",
    "    'R_AGE_IMP',    # 5. Age\n",
    "    'R_RACE',       # 6. Racial/Ethnic Identity\n",
    "    'PTUSED',       # 7. PTUSED\n",
    "    'R_RELAT',      # 8. Household Role\n",
    "    'WORKER',       # 9. Employment Status\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a7d3046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate SCHTYP attribute from persons\n",
    "per_df['IS_STUDENT'] = (per_df['SCHTYP'] == 1).astype(int)\n",
    "stdcnt_series = per_df.groupby('HOUSEID')['IS_STUDENT'].sum()\n",
    "hh_df['STDCNT'] = hh_df['HOUSEID'].map(stdcnt_series)\n",
    "\n",
    "# Drop unusing columns\n",
    "hh_df = hh_df[nhts_household_columns]\n",
    "per_df = per_df[nhts_person_columns]\n",
    "\n",
    "print(len(hh_df.columns), len(per_df.columns))\n",
    "combined_df = per_df.merge(hh_df, on='HOUSEID', how='left')\n",
    "len(combined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c1dbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRIVER: [ 1  2 -1][1 2 3]\n",
      "EDUC: [ 3  2  5  4  1 -1 -8 -7][3 2 5 4 1 6 7]\n",
      "OCCAT: [-1  2  4  3 -9  1 97 -8 -7][6 2 4 3 7 1 5]\n",
      "R_SEX_IMP: [2 1][2 1]\n",
      "R_AGE_IMP: [67 66 28 55 49 45 68 72 82 78 44 40 50 39 38 30 33 75 61 59 22 54 57 25\n",
      " 29  6  5 52 56 86 69 87 31 76 51 17 64 37  7 63 65 24 46 14 23 58 60 73\n",
      " 85 18 19 77 81 47 42 15 13 92 35 62 70 12 36 26 41 16 11 34 48 53 10  8\n",
      " 74 32 20  9 79 43 27 71 21 83 80 84 88][63 62 24 51 45 41 64 68 78 74 40 36 46 35 34 26 29 71 57 55 18 50 53 21\n",
      " 25  2  1 48 52 82 65 83 27 72 47 13 60 33  3 59 61 20 42 10 19 54 56 69\n",
      " 81 14 15 73 77 43 38 11  9 85 31 58 66  8 32 22 37 12  7 30 44 49  6  4\n",
      " 70 28 16  5 75 39 23 67 17 79 76 80 84]\n",
      "R_RACE: [ 2  1  6 97  3  4  5 -7 -8][2 1 6 7 3 4 5 8]\n",
      "PTUSED: [ 0 20  5 22 27  1 21  2 30 10  8  3 18 15 25  6  4 12  7 16 24 17 11 -8\n",
      " -7 28 19 13  9 14 23 26 29 -9][ 1 21  6 23 28  2 22  3 31 11  9  4 19 16 26  7  5 13  8 17 25 18 12 32\n",
      " 29 20 14 10 15 24 27 30]\n",
      "R_RELAT: [ 1  2  3  7  5  4  6 -9 -7 -8][1 2 3 7 5 4 6 8]\n",
      "GT1JBLWK: [-1  2  1 -9 -8 -7][3 2 1 4]\n",
      "WORKER: [ 2  1 -1 -9][2 1 3 4]\n",
      "WRK_HOME: [-1  2  1 -9 -7 -8][3 2 1 4]\n",
      "HHFAMINC: [ 7  8 10  3  5 11  9  4  6  1 -7  2 -8 -9][ 7  8 10  3  5 11  9  4  6  1 12  2]\n",
      "HHSIZE: [3 2 1 4 5][3 2 1 4 5]\n",
      "HHVEHCNT: [ 5  4  2  6  1  3  0  7 12  9  8 10 11][ 6  5  3  7  2  4  1  8 13 10  9 11 12]\n",
      "HOMEOWN: [ 1  2 97 -7 -8][1 2 3 4]\n",
      "STDCNT: [0 2 1 3 4][1 3 2 4 5]\n",
      "DRVRCNT: [3 2 1 0 4 5][4 3 2 1 5 6]\n",
      "LIF_CYC: [10  2  1  4  9  3  8  6  5  7 -9][10  2  1  4  9  3  8  6  5  7 11]\n",
      "WRKCOUNT: [1 2 0 3 4 5][2 3 1 4 5 6]\n",
      "URBRUR: [1 2][1 2]\n",
      "HBRESDN: [  300  7000   750  1500    50 17000  3000 30000    -9][3 7 4 5 1 8 6 9 2]\n",
      "HBPPOPDN: [  750   300 17000  1500  3000    50 30000  7000    -9][4 3 8 5 6 1 9 7 2]\n",
      "HBHTNRNT: [20  5 60 50 40 30 70  0 80 90 95 -9][ 3  2  7  6  5  4  8  1  9 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "# Redefine Indice starting from 0 (conventional procedure to make equal interval between codes)\n",
    "att_dict = dict()\n",
    "for col in combined_df.columns:\n",
    "    if col in ['HOUSEID', 'PERSONID']: continue\n",
    "    label_dict = dict()\n",
    "    print(f\"{col}: {combined_df[col].unique()}\", end='')\n",
    "    \n",
    "    # -7이하는 99로 변환, -1은 98로 변환\n",
    "    combined_df[col] = combined_df[col].apply(lambda x: 99 if x<=-7 else x)\n",
    "    combined_df[col] = combined_df[col].apply(lambda x: 98 if x==-1 else x)\n",
    "    \n",
    "    # 오름차순 정렬 => [유효 값, ..., Appropriate skip,결측치] 순으로 정렬됨\n",
    "    unique_vals = sorted(combined_df[col].unique())\n",
    "\n",
    "    # 1부터 시작하는 label로 변환\n",
    "    for new, old in enumerate(unique_vals):\n",
    "        label_dict[old] = new + 1\n",
    "    combined_df[col] = combined_df[col].apply(lambda x: label_dict[x])\n",
    "    print(f\"{combined_df[col].unique()}\")\n",
    "    \n",
    "    # 0-based label => original label 로 복원하기 위한 dictionary\n",
    "    att_dict[col] = dict()\n",
    "    for old in label_dict.keys():\n",
    "        new = label_dict[old]\n",
    "        att_dict[col][new] = old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef30d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(OUTPUT_PERSONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8bef358",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_ids_df = pd.read_csv('C:/Users/user/PTV_Intern/src/DeepAM/dataset/person_ids.csv', index_col=0)\n",
    "all_person_df = pd.read_csv(OUTPUT_PERSONS_PATH, index_col=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
